<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Pose Tracker</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .gradient-bg {
            background: linear-gradient(-45deg, #1a202c, #2d3748, #4a5568, #2d3748);
            background-size: 400% 400%;
            animation: gradient 15s ease infinite;
        }
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        .input_video {
            display: none;
        }
        .output_canvas {
            width: 100%;
            height: auto;
            border-radius: 0.5rem;
        }
        textarea:focus {
            outline: none;
            box-shadow: 0 0 0 2px rgba(59, 130, 246, 0.5); /* focus:ring-blue-500 */
        }
    </style>
</head>
<body class="gradient-bg text-white min-h-screen flex items-center justify-center">

    <!-- Info/Landing Page Section -->
    <div id="launchPage" class="text-center p-8 max-w-3xl mx-auto">
        <header class="mb-8">
            <h1 class="text-4xl md:text-6xl font-black mb-2 tracking-tight">
                üè• AI-Integrated Medical Surveillance Systems
            </h1>
            <h2 class="text-xl md:text-2xl font-semibold text-blue-300 mb-4">
                Transform Your Clinic with Intelligent Patient Management
            </h2>
        </header>

        <main class="space-y-8">
            <section class="bg-gray-800 bg-opacity-80 rounded-lg p-6 shadow-lg">
                <h3 class="text-2xl font-bold mb-2 text-blue-400">Why Choose Us?</h3>
                <ul class="text-left text-gray-200 space-y-2">
                    <li>‚úÖ <b>Save 40% of staff time</b> by automating manual processes</li>
                    <li>‚úÖ <b>AI facial recognition</b> for instant, secure patient check-in</li>
                    <li>‚úÖ <b>Real-time monitoring</b> and compliance alerts</li>
                    <li>‚úÖ <b>Seamless EMR integration</b> and HIPAA-compliant security</li>
                    <li>‚úÖ <b>Measurable ROI</b>: 95% faster check-ins, 87% less wait time</li>
                </ul>
            </section>

            <section class="bg-gray-800 bg-opacity-80 rounded-lg p-6 shadow-lg">
                <h3 class="text-2xl font-bold mb-2 text-blue-400">How It Works</h3>
                <ol class="text-left text-gray-200 space-y-1 list-decimal list-inside">
                    <li><b>Preparation:</b> Analyze your clinic's workflow and identify bottlenecks</li>
                    <li><b>Engagement:</b> Connect with stakeholders and tailor the solution</li>
                    <li><b>Presentation:</b> Demonstrate real-world impact and live AI tracking</li>
                    <li><b>Pilot:</b> Quick setup, live trial, and measurable results in weeks</li>
                </ol>
            </section>

            <section class="bg-gray-800 bg-opacity-80 rounded-lg p-6 shadow-lg">
                <h3 class="text-2xl font-bold mb-2 text-blue-400">Key Features</h3>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-left text-gray-200">
                    <div>
                        <ul class="space-y-1">
                            <li>üîê <b>Smart Patient Recognition</b></li>
                            <li>‚òÅÔ∏è <b>Automated Check-In</b></li>
                            <li>üìä <b>Intelligent Monitoring</b></li>
                            <li>üõ°Ô∏è <b>Enterprise Security</b></li>
                        </ul>
                    </div>
                    <div>
                        <ul class="space-y-1">
                            <li>üé§ <b>Voice Recognition (optional)</b></li>
                            <li>‚åö <b>Wearable Integration</b></li>
                            <li>ü§ñ <b>Predictive Analytics</b></li>
                            <li>üì± <b>Mobile Apps</b></li>
                        </ul>
                    </div>
                </div>
            </section>

            <section class="bg-gray-800 bg-opacity-80 rounded-lg p-6 shadow-lg">
                <h3 class="text-2xl font-bold mb-2 text-blue-400">Ready to Transform Your Clinic?</h3>
                <p class="text-gray-200 mb-4">
                    Schedule a personalized demo, start a risk-free pilot, and join the future of healthcare. <br>
                    <span class="italic text-blue-200">"Don't just manage patients‚Äîdelight them with efficiency."</span>
                </p>
                <button id="launchButton"
                    class="inline-block bg-blue-600 hover:bg-blue-700 text-white font-bold py-4 px-10 rounded-full text-xl transition-transform transform hover:scale-105 duration-300 shadow-lg">
                    Get Started
                </button>
            </section>
        </main>

        <footer class="mt-12 text-gray-500 text-sm">
            &copy; 2024 AI-Integrated Medical Surveillance Systems. All rights reserved.
        </footer>
    </div>

    <!-- Tracker App Section (Initially Hidden) -->
    <div id="trackerPage" class="hidden w-full max-w-5xl mx-auto p-4">
        <div class="bg-gray-800 p-4 rounded-lg shadow-lg">
            <!-- Video and Canvas Container -->
            <div class="relative">
                <video class="input_video"></video>
                <canvas class="output_canvas" width="1280px" height="720px"></canvas>
                 <!-- Loading Spinner -->
                <div id="loading" class="absolute top-0 left-0 w-full h-full bg-gray-900 bg-opacity-75 flex justify-center items-center rounded-lg hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-32 w-32 animate-spin"></div>
                </div>
            </div>

            <!-- User Input Text Box -->
            <textarea id="inputTextBox"
                      class="mt-4 p-4 w-full bg-gray-900 rounded-lg text-gray-300 border border-gray-700 transition"
                      rows="3"
                      placeholder="Type a command (e.g., 'do a pushup') and press Enter..."></textarea>

            <!-- Controls -->
            <div class="flex justify-center items-center space-x-4 mt-4">
                <button id="backButton" class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded-lg transition duration-300">
                    Back to Home
                </button>
                <button id="startButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-lg transition duration-300">
                    Start Tracking
                </button>
                <button id="stopButton" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-4 rounded-lg transition duration-300" disabled>
                    Stop Tracking
                </button>
            </div>
        </div>
    </div>


    <script type="module">
        // --- Page Navigation Elements ---
        const launchPage = document.getElementById('launchPage');
        const trackerPage = document.getElementById('trackerPage');
        const launchButton = document.getElementById('launchButton');
        const backButton = document.getElementById('backButton');

        // --- Pose Tracker Elements ---
        const videoElement = document.getElementsByClassName('input_video')[0];
        const canvasElement = document.getElementsByClassName('output_canvas')[0];
        const canvasCtx = canvasElement.getContext('2d');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const loadingElement = document.getElementById('loading');
        const inputTextBox = document.getElementById('inputTextBox');

        let camera = null;
        let pose = null;
        let displayText = '';

        // --- Action Recognition State ---
        let actionSequence = null;
        let currentStepIndex = 0;

        // --- Landmark Name Mapping ---
        const landmarkNames = [
            'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer', 'right_eye_inner', 'right_eye', 'right_eye_outer',
            'left_ear', 'right_ear', 'mouth_left', 'mouth_right', 'left_shoulder', 'right_shoulder', 'left_elbow',
            'right_elbow', 'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky', 'left_index', 'right_index',
            'left_thumb', 'right_thumb', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle',
            'left_heel', 'right_heel', 'left_foot_index', 'right_foot_index'
        ];

        // --- Page Navigation Logic ---
        launchButton.addEventListener('click', () => {
            launchPage.classList.add('hidden');
            trackerPage.classList.remove('hidden');
            document.body.classList.remove('gradient-bg', 'flex', 'items-center', 'justify-center');
            document.body.classList.add('bg-gray-900');
        });

        backButton.addEventListener('click', () => {
            stopTracking();
            trackerPage.classList.add('hidden');
            launchPage.classList.remove('hidden');
            document.body.classList.add('gradient-bg', 'flex', 'items-center', 'justify-center');
            document.body.classList.remove('bg-gray-900');
        });

        // --- Condition Checking Logic ---
        function checkCondition(condition, landmarks) {
            const l1 = landmarks[landmarkNames.indexOf(condition.landmark1)];
            const l2 = landmarks[landmarkNames.indexOf(condition.landmark2)];
            if (!l1 || !l2) return false; // Landmark not visible

            const threshold = condition.threshold || 0.05; // Default proximity threshold

            switch (condition.relationship) {
                case 'is_above': return l1.y < l2.y;
                case 'is_below': return l1.y > l2.y;
                case 'is_left_of': return l1.x < l2.x;
                case 'is_right_of': return l1.x > l2.x;
                case 'is_close_to': {
                    const dx = l1.x - l2.x;
                    const dy = l1.y - l2.y;
                    return Math.sqrt(dx * dx + dy * dy) < threshold;
                }
                default: return false;
            }
        }

        // --- Pose Tracker Logic ---
        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

            if (results.poseLandmarks) {
                // If there's an active action sequence, check for completion
                if (actionSequence && actionSequence.steps[currentStepIndex]) {
                    const currentStep = actionSequence.steps[currentStepIndex];
                    let allConditionsMet = true;
                    for (const condition of currentStep.conditions) {
                        if (!checkCondition(condition, results.poseLandmarks)) {
                            allConditionsMet = false;
                            break;
                        }
                    }

                    if (allConditionsMet) {
                        currentStepIndex++; // Move to the next step
                        if (currentStepIndex >= actionSequence.steps.length) {
                            // Action complete
                            displayText = `${actionSequence.actionName} Complete!`;
                            actionSequence = null;
                            currentStepIndex = 0;
                            setTimeout(() => { displayText = ''; }, 2000);
                        } else {
                            // Update instruction for the next step
                            displayText = actionSequence.steps[currentStepIndex].instruction;
                        }
                    }
                }

                // Draw skeleton and landmarks
                drawConnectors(canvasCtx, results.poseLandmarks, POSE_CONNECTIONS, { color: '#00FF00', lineWidth: 4 });
                drawLandmarks(canvasCtx, results.poseLandmarks, { color: '#FF0000', radius: 2 });
            }

            // Draw the display text
            if (displayText) {
                canvasCtx.fillStyle = 'white';
                canvasCtx.strokeStyle = 'black';
                canvasCtx.lineWidth = 5;
                canvasCtx.font = 'bold 60px Inter';
                canvasCtx.textAlign = 'center';
                const x = canvasElement.width / 2;
                const y = canvasElement.height - 60;
                canvasCtx.strokeText(displayText, x, y);
                canvasCtx.fillText(displayText, x, y);
            }
            canvasCtx.restore();
        }

        function initializePose() {
            pose = new Pose({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}` });
            pose.setOptions({ modelComplexity: 1, smoothLandmarks: true, minDetectionConfidence: 0.6, minTrackingConfidence: 0.6 });
            pose.onResults(onResults);
        }

        async function startTracking() {
            loadingElement.classList.remove('hidden');
            startButton.disabled = true;
            backButton.disabled = true;
            if (!pose) initializePose();
            camera = new Camera(videoElement, { onFrame: async () => await pose.send({ image: videoElement }), width: 1280, height: 720 });
            try {
                await camera.start();
                loadingElement.classList.add('hidden');
                stopButton.disabled = false;
                backButton.disabled = false;
            } catch (error) {
                console.error("Failed to start camera:", error);
                loadingElement.classList.add('hidden');
                startButton.disabled = false;
                backButton.disabled = false;
            }
        }

        function stopTracking() {
            if (camera) { camera.stop(); camera = null; }
            displayText = '';
            actionSequence = null;
            currentStepIndex = 0;
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            startButton.disabled = false;
            stopButton.disabled = true;
        }

        // --- Gemini API Call ---
        async function getActionSequenceFromAI(command) {
            displayText = 'Analyzing action...';
            const apiKey = ""; // Leave empty, will be handled by the environment
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

            const prompt = `
                You are a virtual fitness coach. Your task is to take a user's command and break it down into a sequence of simple, checkable body poses.
                Respond with ONLY a JSON object that follows this exact schema. Do not include any other text or markdown.

                The user wants to perform the action: "${command}"

                The available landmarks are: ${landmarkNames.join(', ')}.
                The available relationships are: 'is_above', 'is_below', 'is_left_of', 'is_right_of', 'is_close_to'.

                The JSON response must have an "actionName", and a "steps" array. Each step must have a "name", an "instruction" for the user, and an array of "conditions".
                Each condition must have a "landmark1", a "landmark2", and a "relationship". For 'is_close_to', you can optionally add a "threshold" (0.0 to 1.0, default is 0.05).
                Keep the instructions short and clear. Make the sequence logical for performing the action.
            `;

            const payload = {
                contents: [{ role: "user", parts: [{ text: prompt }] }],
                generationConfig: { responseMimeType: "application/json" }
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (!response.ok) {
                    throw new Error(`API call failed with status: ${response.status}`);
                }
                const result = await response.json();

                if (result.candidates && result.candidates[0].content && result.candidates[0].content.parts[0]) {
                    const jsonText = result.candidates[0].content.parts[0].text;
                    return JSON.parse(jsonText);
                } else {
                    throw new Error("Invalid response structure from AI.");
                }
            } catch (error) {
                console.error("Error fetching from AI:", error);
                displayText = "Sorry, I couldn't understand that action.";
                setTimeout(() => { displayText = ''; }, 3000);
                return null;
            }
        }


        // --- Event Listeners ---
        startButton.addEventListener('click', startTracking);
        stopButton.addEventListener('click', stopTracking);
        
        inputTextBox.addEventListener('keydown', async (event) => {
            if (event.key === 'Enter') {
                event.preventDefault();
                const command = inputTextBox.value.trim();
                if (command === '') return;
                
                inputTextBox.value = '';
                stopTracking(); // Reset state before starting new action
                await startTracking(); // Ensure camera is running

                actionSequence = await getActionSequenceFromAI(command);
                
                if (actionSequence && actionSequence.steps && actionSequence.steps.length > 0) {
                    currentStepIndex = 0;
                    displayText = actionSequence.steps[0].instruction;
                }
            }
        });

        window.addEventListener('beforeunload', () => { if (camera) camera.stop(); });
    </script>
</body>
</html>